{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchsample.transforms import *\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEVICE_ID = 3\n",
    "#DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "#torch.cuda.set_device(DEVICE_ID)\n",
    "# bWQ2aGt1cW9pYmVodGJubXUyOW5yNmU0c2k6MzQ2MzUxNmEtMzA5OC00ZWE3LWEwNzEtNzk4ZTUyMWM3MzMy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Для запуска без GPU раскомментировать и закоментировать код выше\n",
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "class Rotate(object):\n",
    "\n",
    "    def __init__(self, \n",
    "                 value,\n",
    "                 interp='bilinear',\n",
    "                 lazy=False):\n",
    "        \"\"\"\n",
    "        Randomly rotate an image between (-degrees, degrees). If the image\n",
    "        has multiple channels, the same rotation will be applied to each channel.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        rotation_range : integer or float\n",
    "            image will be rotated between (-degrees, degrees) degrees\n",
    "\n",
    "        interp : string in {'bilinear', 'nearest'} or list of strings\n",
    "            type of interpolation to use. You can provide a different\n",
    "            type of interpolation for each input, e.g. if you have two\n",
    "            inputs then you can say `interp=['bilinear','nearest']\n",
    "\n",
    "        lazy    : boolean\n",
    "            if true, only create the affine transform matrix and return that\n",
    "            if false, perform the transform on the tensor and return the tensor\n",
    "        \"\"\"\n",
    "        self.value = value\n",
    "        self.interp = interp\n",
    "        self.lazy = lazy\n",
    "\n",
    "    def __call__(self, *inputs):\n",
    "        if not isinstance(self.interp, (tuple,list)):\n",
    "            interp = [self.interp]*len(inputs)\n",
    "        else:\n",
    "            interp = self.interp\n",
    "\n",
    "        theta = math.pi / 180 * self.value\n",
    "        rotation_matrix = th.FloatTensor([[math.cos(theta), -math.sin(theta), 0],\n",
    "                                          [math.sin(theta), math.cos(theta), 0],\n",
    "                                          [0, 0, 1]])\n",
    "        if self.lazy:\n",
    "            return rotation_matrix\n",
    "        else:\n",
    "            outputs = []\n",
    "            for idx, _input in enumerate(inputs):\n",
    "                input_tf = th_affine2d(_input,\n",
    "                                       rotation_matrix,\n",
    "                                       mode=interp[idx],\n",
    "                                       center=True)\n",
    "                outputs.append(input_tf)\n",
    "            return outputs if idx > 1 else outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_affine2d(x, matrix, mode='bilinear', center=True):\n",
    "    \"\"\"\n",
    "    2D Affine image transform on th.Tensor\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x : th.Tensor of size (C, H, W)\n",
    "        image tensor to be transformed\n",
    "\n",
    "    matrix : th.Tensor of size (3, 3) or (2, 3)\n",
    "        transformation matrix\n",
    "\n",
    "    mode : string in {'nearest', 'bilinear'}\n",
    "        interpolation scheme to use\n",
    "\n",
    "    center : boolean\n",
    "        whether to alter the bias of the transform \n",
    "        so the transform is applied about the center\n",
    "        of the image rather than the origin\n",
    "\n",
    "    Example\n",
    "    ------- \n",
    "    >>> import torch\n",
    "    >>> from torchsample.utils import *\n",
    "    >>> x = th.zeros(2,1000,1000)\n",
    "    >>> x[:,100:1500,100:500] = 10\n",
    "    >>> matrix = th.FloatTensor([[1.,0,-50],\n",
    "    ...                             [0,1.,-50]])\n",
    "    >>> xn = th_affine2d(x, matrix, mode='nearest')\n",
    "    >>> xb = th_affine2d(x, matrix, mode='bilinear')\n",
    "    \"\"\"\n",
    "\n",
    "    if matrix.dim() == 2:\n",
    "        matrix = matrix[:2,:]\n",
    "        matrix = matrix.unsqueeze(0)\n",
    "    elif matrix.dim() == 3:\n",
    "        if matrix.size()[1:] == (3,3):\n",
    "            matrix = matrix[:,:2,:]\n",
    "\n",
    "    A_batch = matrix[:,:,:2]\n",
    "    if A_batch.size(0) != x.size(0):\n",
    "        A_batch = A_batch.repeat(x.size(0),1,1)\n",
    "    b_batch = matrix[:,:,2].unsqueeze(1)\n",
    "\n",
    "    # make a meshgrid of normal coordinates\n",
    "    _coords = th_iterproduct(x.size(1),x.size(2))\n",
    "    coords = _coords.unsqueeze(0).repeat(x.size(0),1,1).float()\n",
    "\n",
    "    if center:\n",
    "        # shift the coordinates so center is the origin\n",
    "        coords[:,:,0] = coords[:,:,0] - (x.size(1) / 2. - 0.5)\n",
    "        coords[:,:,1] = coords[:,:,1] - (x.size(2) / 2. - 0.5)\n",
    "    # apply the coordinate transformation\n",
    "    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n",
    "\n",
    "    if center:\n",
    "        # shift the coordinates back so origin is origin\n",
    "        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(1) / 2. - 0.5)\n",
    "        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(2) / 2. - 0.5)\n",
    "\n",
    "    # map new coordinates using bilinear interpolation\n",
    "    if mode == 'nearest':\n",
    "        x_transformed = th_nearest_interp2d(x.contiguous(), new_coords)\n",
    "    elif mode == 'bilinear':\n",
    "        x_transformed = th_bilinear_interp2d(x.contiguous(), new_coords)\n",
    "\n",
    "    return x_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_bilinear_interp2d(input, coords):\n",
    "    \"\"\"\n",
    "    bilinear interpolation in 2d\n",
    "    \"\"\"\n",
    "    x = th.clamp(coords[:,:,0], 0, input.size(1)-2)\n",
    "    x0 = x.floor()\n",
    "    x1 = x0 + 1\n",
    "    y = th.clamp(coords[:,:,1], 0, input.size(2)-2)\n",
    "    y0 = y.floor()\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    stride = th.FloatTensor(input.stride())\n",
    "    x0_ix = x0.mul(stride[1]).long()\n",
    "    x1_ix = x1.mul(stride[1]).long()\n",
    "    y0_ix = y0.mul(stride[2]).long()\n",
    "    y1_ix = y1.mul(stride[2]).long()\n",
    "\n",
    "    input_flat = input.view(input.size(0),-1)\n",
    "\n",
    "    vals_00 = input_flat.gather(1, x0_ix.add(y0_ix))\n",
    "    vals_10 = input_flat.gather(1, x1_ix.add(y0_ix))\n",
    "    vals_01 = input_flat.gather(1, x0_ix.add(y1_ix))\n",
    "    vals_11 = input_flat.gather(1, x1_ix.add(y1_ix))\n",
    "    \n",
    "    xd = x - x0\n",
    "    yd = y - y0\n",
    "    xm = 1 - xd\n",
    "    ym = 1 - yd\n",
    "\n",
    "    x_mapped = (vals_00.mul(xm).mul(ym) +\n",
    "                vals_10.mul(xd).mul(ym) +\n",
    "                vals_01.mul(xm).mul(yd) +\n",
    "                vals_11.mul(xd).mul(yd))\n",
    "\n",
    "    return x_mapped.view_as(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_iterproduct(*args):\n",
    "    return th.from_numpy(np.indices(args).reshape((len(args),-1)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [PIL.Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Надо поменять пути на свои до файлов с kaggle\n",
    "DATA_PATH  = os.getcwd()  + '/'\n",
    "train_path = 'homework_4.train.npy'\n",
    "test_path  = 'homework_4_no_classes.test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mean = np.mean([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))\n",
    "np_std = np.std([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform_norm = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = CifarDataset(DATA_PATH + train_path, transform=cifar_transform_norm)\n",
    "dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_test_norm = CifarDataset(DATA_PATH + test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "def train_network(a_net, \n",
    "                  a_device,\n",
    "                  dataloader_train_norm=dataloader_train_norm,\n",
    "                  a_epochs=1000,\n",
    "                  a_batch_size=128,\n",
    "                  a_lr=0.08):\n",
    "    \n",
    "    train_acc = []\n",
    "    net = a_net.to(a_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    \n",
    "    for epoch in range(a_epochs):  # loop over the dataset multiple times\n",
    "        if (epoch+1)%5 == 0:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr*0.98, weight_decay=0.0001, momentum=0.9) \n",
    "        elif epoch == 123:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr*0.98, weight_decay=0.0001, momentum=0.9) \n",
    "        \n",
    "        net = net.train()        \n",
    "        epoch_accuracy = 0.0\n",
    "        epoch_iters = 0\n",
    "        for item in dataloader_train_norm:\n",
    "            \n",
    "            epoch_iters += 1\n",
    "            \n",
    "            #get_augumentation(item[0])\n",
    "            inputs = item[0].to(a_device)\n",
    "            labels = item[1].long().to(a_device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_accuracy += accuracy_score(labels, prediction2classes(outputs))\n",
    "\n",
    "        epoch_accuracy /= epoch_iters\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        \n",
    "        print(\"Epoch \", epoch, round(train_acc[-1], 4))\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    plt.plot(train_acc, label='Train')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augumentation(batch):\n",
    "    #new_batch = torch.FloatTensor(batch.size()).fill_(0)\n",
    "    for i, tensor in enumerate(batch):\n",
    "        choise = np.random.randint(0, 5)\n",
    "        #if choise == np.random.randint(0, 500):\n",
    "            #print('change gaus ', i)\n",
    "            #tensor = tensor + torch.FloatTensor(tensor.size()).uniform_(-0.2, 0.2)\n",
    "        if choise == np.random.randint(0, 5):\n",
    "            #print('change rotate', i)\n",
    "            tensor = Rotate(90*((np.random.randint(0, 9))%4))(tensor)\n",
    "        else:\n",
    "            tensor = tensor\n",
    "    #return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StupidDenseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StupidDenseNet, self).__init__()\n",
    "        \n",
    "        #Один из способов задать сеть - это задать последовательность слоев через Sequential\n",
    "        self.classifier = nn.Sequential()\n",
    "        self.classifier.add_module('lin1', nn.Linear(3*32*32, 500))\n",
    "        self.classifier.add_module('sig1', torch.nn.Sigmoid())\n",
    "        self.classifier.add_module('lin2', nn.Linear(3*32*32, 500))\n",
    "        self.classifier.add_module('sig2', torch.nn.Sigmoid())\n",
    "        self.classifier.add_module('lin3', nn.Linear(3*32*32, 500))\n",
    "        self.classifier.add_module('sig3', torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        ### Другой способ задания сети - это описать слои и в forward их применять явно\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        #Увеличиваем кол-во выходных слоев с 84 - до 84*2 - потому что классов 100\n",
    "        self.fc2 = nn.Linear(120, 84*2)\n",
    "        self.fc3 = nn.Linear(84*2, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLE_COEF = 2\n",
    "\n",
    "def conv3x3(a_in_planes, a_out_planes, a_stride=1):\n",
    "    \"\"\"\n",
    "    Основной строительный блок конволюций для ResNet\n",
    "    Включает в себя padding=1 - чтобы размерность сохранялась после его применения\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(a_in_planes, a_out_planes,  stride=a_stride,\n",
    "                     kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "def x_downsample(a_in_channels):\n",
    "     return nn.Conv2d(a_in_channels, \n",
    "               a_in_channels*DOWNSAMPLE_COEF,\n",
    "               kernel_size=1,\n",
    "               stride=2,\n",
    "               bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResidualBlock(nn.Module):\n",
    "    def __init__(self, a_in_channels, make_downsample=False, use_skip_connection=True):\n",
    "        super(CifarResidualBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        \n",
    "        if make_downsample: coef = DOWNSAMPLE_COEF\n",
    "        else: coef = 1  \n",
    "            \n",
    "        ### TODO - нужно описать используемые блоки\n",
    "        planes = int(coef*a_in_channels)\n",
    "        \n",
    "        self.conv1 = conv3x3(a_in_channels, planes, a_stride=coef)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        if make_downsample:\n",
    "            self.downsample = x_downsample(a_in_channels)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        ###TODO - описать forward блок с учетом флагов make_downsample и use_skip_connection\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            #print('1', out.size())\n",
    "            if self.use_skip_connection:\n",
    "                residual = self.downsample(x)\n",
    "            #out = self.downsample(out)\n",
    "            #print('2', out.size(), residual.size())\n",
    "         \n",
    "        #print('3', out.size())\n",
    "        \n",
    "        if self.use_skip_connection:\n",
    "            out += residual\n",
    "        #print('4', out.size())\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResidualBottleneckBlock(nn.Module):\n",
    "    \n",
    "    BOTTLENECK_COEF = 4\n",
    "    \n",
    "    def __init__(self, a_in_channels, make_downsample=False, use_skip_connection=True):\n",
    "        super(CifarResidualBottleneckBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        \n",
    "        if make_downsample: coef = DOWNSAMPLE_COEF\n",
    "        else: coef = 1  \n",
    "            \n",
    "        planes = int(coef*a_in_channels/self.BOTTLENECK_COEF)\n",
    "        planes_out = int(a_in_channels*coef)\n",
    "        ### TODO - нужно описать используемые блоки\n",
    "        self.conv1 = nn.Conv2d(a_in_channels, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, stride=coef, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes_out, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        if make_downsample:\n",
    "            self.downsample = nn.Conv2d(a_in_channels, \n",
    "               planes_out,\n",
    "               kernel_size=1,\n",
    "               stride=2,\n",
    "               bias=False)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        ###TODO - описать forward блок с учетом флагов make_downsample и use_skip_connection\n",
    "        residual = x\n",
    "        #print('1', x.size())\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            #print('1', out.size())\n",
    "            if self.use_skip_connection:\n",
    "                residual = self.downsample(x)\n",
    "            #out = self.downsample(out)\n",
    "            #print('2', out.size(), residual.size())\n",
    "         \n",
    "        #print('3', out.size())\n",
    "        \n",
    "        if self.use_skip_connection:\n",
    "            out += residual\n",
    "            \n",
    "        #print('4', out.size())\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers=[2,2,2,2]):\n",
    "        super(CifarResNet, self).__init__()\n",
    "        \n",
    "        #TODO нужно добавить блоков resnet и других слоев при необходимости\n",
    "        self.out_chanels = 64\n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module('conv1', nn.Conv2d(3, self.out_chanels, kernel_size=7, stride=2, padding=3, bias=False))\n",
    "        self.features.add_module('bn1', nn.BatchNorm2d(self.out_chanels))\n",
    "        self.features.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.features.add_module('maxpool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        #...\n",
    "        for i in range(layers[0]):\n",
    "            self.features.add_module('res_block1'+str(i+1), CifarResidualBottleneckBlock(self.out_chanels))\n",
    "            \n",
    "        #self.features.add_module('res_block2'+str(1), CifarResidualBlock(64, make_downsample=True))\n",
    "        for i in range(layers[1]):\n",
    "            self.features.add_module('res_block2'+str(i+1), CifarResidualBottleneckBlock(self.out_chanels, make_downsample=False))\n",
    "            \n",
    "        for i in range(layers[2]):\n",
    "            self.features.add_module('res_block3'+str(i+1), CifarResidualBottleneckBlock(self.out_chanels, make_downsample=False))\n",
    "                                     \n",
    "        for i in range(layers[3]):\n",
    "            self.features.add_module('res_block4'+str(i+1), CifarResidualBottleneckBlock(self.out_chanels, make_downsample=False))\n",
    "        #...\n",
    "        \n",
    "        self.global_avg_pooling = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.fc_classifier = nn.Linear(self.out_chanels*4, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #print(x.size())\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = x.view((x.size()[0], -1))\n",
    "        #print(x.size())\n",
    "        x = self.fc_classifier(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_net = StupidDenseNet()\n",
    "#%time train_network(dense_net, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenet = LeNet()\n",
    "#%time train_network(lenet, torch.device('cpu'), a_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenet = LeNet()\n",
    "#%time train_network(lenet, torch.device(DEVICE), a_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenet = LeNet()\n",
    "#%time train_network(lenet, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 0.0601\n",
      "Epoch  1 0.1438\n",
      "Epoch  2 0.2011\n",
      "Epoch  3 0.2464\n",
      "Epoch  4 0.2813\n",
      "Epoch  5 0.3109\n",
      "Epoch  6 0.3346\n",
      "Epoch  7 0.3562\n",
      "Epoch  8 0.378\n",
      "Epoch  9 0.3927\n",
      "Epoch  10 0.4075\n",
      "Epoch  11 0.4206\n",
      "Epoch  12 0.4315\n",
      "Epoch  13 0.4409\n",
      "Epoch  14 0.4506\n",
      "Epoch  15 0.4583\n",
      "Epoch  16 0.466\n",
      "Epoch  17 0.4714\n",
      "Epoch  18 0.4798\n",
      "Epoch  19 0.4813\n",
      "Epoch  20 0.4847\n",
      "Epoch  21 0.4893\n",
      "Epoch  22 0.497\n",
      "Epoch  23 0.4965\n",
      "Epoch  24 0.5025\n",
      "Epoch  25 0.5051\n",
      "Epoch  26 0.5088\n",
      "Epoch  27 0.5141\n",
      "Epoch  28 0.5132\n",
      "Epoch  29 0.5184\n",
      "Epoch  30 0.5222\n",
      "Epoch  31 0.5188\n",
      "Epoch  32 0.5253\n",
      "Epoch  33 0.5247\n",
      "Epoch  34 0.5301\n",
      "Epoch  35 0.5274\n",
      "Epoch  36 0.531\n",
      "Epoch  37 0.534\n",
      "Epoch  38 0.5352\n",
      "Epoch  39 0.5385\n",
      "Epoch  40 0.538\n",
      "Epoch  41 0.5396\n",
      "Epoch  42 0.5408\n",
      "Epoch  43 0.5435\n",
      "Epoch  44 0.5453\n",
      "Epoch  45 0.5478\n",
      "Epoch  46 0.545\n",
      "Epoch  47 0.5477\n",
      "Epoch  48 0.5471\n",
      "Epoch  49 0.55\n",
      "Epoch  50 0.5527\n",
      "Epoch  51 0.5541\n",
      "Epoch  52 0.5515\n",
      "Epoch  53 0.5516\n",
      "Epoch  54 0.5579\n",
      "Epoch  55 0.5569\n",
      "Epoch  56 0.5573\n",
      "Epoch  57 0.5587\n",
      "Epoch  58 0.5555\n",
      "Epoch  59 0.5635\n",
      "Epoch  60 0.5626\n",
      "Epoch  61 0.5623\n",
      "Epoch  62 0.563\n",
      "Epoch  63 0.5646\n",
      "Epoch  64 0.5648\n",
      "Epoch  65 0.5645\n",
      "Epoch  66 0.5655\n",
      "Epoch  67 0.5642\n",
      "Epoch  68 0.5687\n",
      "Epoch  69 0.5704\n",
      "Epoch  70 0.5682\n",
      "Epoch  71 0.5699\n",
      "Epoch  72 0.5715\n",
      "Epoch  73 0.5711\n",
      "Epoch  74 0.5726\n",
      "Epoch  75 0.5727\n",
      "Epoch  76 0.573\n",
      "Epoch  77 0.5738\n",
      "Epoch  78 0.5736\n",
      "Epoch  79 0.5734\n",
      "Epoch  80 0.5741\n",
      "Epoch  81 0.5772\n",
      "Epoch  82 0.5771\n",
      "Epoch  83 0.5752\n",
      "Epoch  84 0.5776\n",
      "Epoch  85 0.5777\n",
      "Epoch  86 0.5764\n",
      "Epoch  87 0.5742\n",
      "Epoch  88 0.5799\n",
      "Epoch  89 0.5822\n",
      "Epoch  90 0.579\n",
      "Epoch  91 0.5791\n",
      "Epoch  92 0.5811\n",
      "Epoch  93 0.58\n",
      "Epoch  94 0.5839\n",
      "Epoch  95 0.5825\n",
      "Epoch  96 0.5814\n",
      "Epoch  97 0.5837\n",
      "Epoch  98 0.5832\n",
      "Epoch  99 0.5854\n",
      "Epoch  100 0.5834\n",
      "Epoch  101 0.5851\n",
      "Epoch  102 0.5818\n",
      "Epoch  103 0.587\n",
      "Epoch  104 0.5871\n",
      "Epoch  105 0.5822\n",
      "Epoch  106 0.5863\n",
      "Epoch  107 0.5817\n",
      "Epoch  108 0.5878\n",
      "Epoch  109 0.5861\n",
      "Epoch  110 0.5837\n",
      "Epoch  111 0.587\n",
      "Epoch  112 0.5877\n",
      "Epoch  113 0.5817\n",
      "Epoch  114 0.5908\n",
      "Epoch  115 0.5905\n",
      "Epoch  116 0.5876\n",
      "Epoch  117 0.5871\n",
      "Epoch  118 0.5906\n",
      "Epoch  119 0.5911\n",
      "Epoch  120 0.5919\n",
      "Epoch  121 0.5872\n",
      "Epoch  122 0.5891\n",
      "Epoch  123 0.5915\n",
      "Epoch  124 0.5907\n",
      "Epoch  125 0.5911\n",
      "Epoch  126 0.5921\n",
      "Epoch  127 0.5875\n",
      "Epoch  128 0.5936\n",
      "Epoch  129 0.5909\n",
      "Epoch  130 0.5921\n",
      "Epoch  131 0.5942\n",
      "Epoch  132 0.5914\n",
      "Epoch  133 0.5937\n",
      "Epoch  134 0.594\n",
      "Epoch  135 0.5916\n",
      "Epoch  136 0.5928\n",
      "Epoch  137 0.5922\n",
      "Epoch  138 0.596\n",
      "Epoch  139 0.5966\n",
      "Epoch  140 0.5965\n",
      "Epoch  141 0.5951\n",
      "Epoch  142 0.5942\n",
      "Epoch  143 0.5933\n",
      "Epoch  144 0.5992\n",
      "Epoch  145 0.5962\n",
      "Epoch  146 0.5953\n",
      "Epoch  147 0.599\n",
      "Epoch  148 0.5965\n",
      "Epoch  149 0.5982\n",
      "Epoch  150 0.5954\n",
      "Epoch  151 0.5964\n",
      "Epoch  152 0.598\n",
      "Epoch  153 0.5938\n",
      "Epoch  154 0.5984\n",
      "Epoch  155 0.599\n",
      "Epoch  156 0.5971\n",
      "Epoch  157 0.5959\n",
      "Epoch  158 0.5965\n",
      "Epoch  159 0.5994\n",
      "Epoch  160 0.5983\n",
      "Epoch  161 0.5983\n",
      "Epoch  162 0.5998\n",
      "Epoch  163 0.5992\n",
      "Epoch  164 0.599\n",
      "Epoch  165 0.6001\n",
      "Epoch  166 0.6014\n",
      "Epoch  167 0.6002\n",
      "Epoch  168 0.5979\n",
      "Epoch  169 0.6026\n",
      "Epoch  170 0.6013\n",
      "Epoch  171 0.5992\n",
      "Epoch  172 0.5977\n",
      "Epoch  173 0.6015\n",
      "Epoch  174 0.5992\n",
      "Epoch  175 0.5983\n",
      "Epoch  176 0.602\n",
      "Epoch  177 0.6003\n",
      "Epoch  178 0.6024\n",
      "Epoch  179 0.6014\n",
      "Epoch  180 0.5996\n",
      "Epoch  181 0.6012\n",
      "Epoch  182 0.6022\n",
      "Epoch  183 0.6033\n",
      "Epoch  184 0.6024\n",
      "Epoch  185 0.603\n",
      "Epoch  186 0.603\n",
      "Epoch  187 0.6025\n",
      "Epoch  188 0.6022\n",
      "Epoch  189 0.6006\n",
      "Epoch  190 0.5982\n",
      "Epoch  191 0.6083\n",
      "Epoch  192 0.6004\n",
      "Epoch  193 0.6022\n",
      "Epoch  194 0.6065\n",
      "Epoch  195 0.6018\n",
      "Epoch  196 0.6039\n",
      "Epoch  197 0.6066\n",
      "Epoch  198 0.5985\n",
      "Epoch  199 0.6047\n",
      "Epoch  200 0.6009\n",
      "Epoch  201 0.6083\n",
      "Epoch  202 0.6059\n",
      "Epoch  203 0.6048\n",
      "Epoch  204 0.6085\n",
      "Epoch  205 0.6069\n",
      "Epoch  206 0.6056\n",
      "Epoch  207 0.6027\n",
      "Epoch  208 0.6073\n",
      "Epoch  209 0.6067\n",
      "Epoch  210 0.6039\n",
      "Epoch  211 0.6059\n",
      "Epoch  212 0.6064\n",
      "Epoch  213 0.6058\n",
      "Epoch  214 0.6049\n",
      "Epoch  215 0.6044\n",
      "Epoch  216 0.6066\n",
      "Epoch  217 0.6067\n",
      "Epoch  218 0.6045\n",
      "Epoch  219 0.6088\n",
      "Epoch  220 0.6044\n",
      "Epoch  221 0.6076\n",
      "Epoch  222 0.6049\n",
      "Epoch  223 0.6079\n",
      "Epoch  224 0.606\n",
      "Epoch  225 0.6075\n",
      "Epoch  226 0.607\n",
      "Epoch  227 0.6063\n",
      "Epoch  228 0.6088\n",
      "Epoch  229 0.6088\n",
      "Epoch  230 0.6043\n",
      "Epoch  231 0.6074\n",
      "Epoch  232 0.6103\n",
      "Epoch  233 0.6075\n",
      "Epoch  234 0.6085\n",
      "Epoch  235 0.6066\n",
      "Epoch  236 0.6054\n",
      "Epoch  237 0.6071\n",
      "Epoch  238 0.6061\n",
      "Epoch  239 0.6104\n",
      "Epoch  240 0.6079\n",
      "Epoch  241 0.6072\n",
      "Epoch  242 0.6096\n",
      "Epoch  243 0.6102\n",
      "Epoch  244 0.6134\n",
      "Epoch  245 0.6092\n",
      "Epoch  246 0.6084\n",
      "Epoch  247 0.6096\n",
      "Epoch  248 0.6106\n",
      "Epoch  249 0.6102\n",
      "Epoch  250 0.6083\n",
      "Epoch  251 0.6089\n",
      "Epoch  252 0.6113\n",
      "Epoch  253 0.6128\n",
      "Epoch  254 0.6109\n",
      "Epoch  255 0.6107\n",
      "Epoch  256 0.6077\n",
      "Epoch  257 0.61\n",
      "Epoch  258 0.6088\n",
      "Epoch  259 0.6113\n",
      "Epoch  260 0.6129\n",
      "Epoch  261 0.6088\n",
      "Epoch  262 0.6111\n",
      "Epoch  263 0.6124\n",
      "Epoch  264 0.6139\n",
      "Epoch  265 0.6093\n",
      "Epoch  266 0.6108\n",
      "Epoch  267 0.6119\n",
      "Epoch  268 0.6088\n",
      "Epoch  269 0.6119\n",
      "Epoch  270 0.6124\n",
      "Epoch  271 0.6108\n",
      "Epoch  272 0.6137\n",
      "Epoch  273 0.6103\n",
      "Epoch  274 0.6127\n"
     ]
    }
   ],
   "source": [
    "resnet = CifarResNet([2, 8, 8, 2])\n",
    "%time train_network(resnet, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Важно переключить сеть в режим eval - иначе dropout будет работать некорректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in dataloader_test_norm:\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_solution = make_solution(dense_net, DEVICE)\n",
    "my_solution = make_solution(resnet, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_solution6.csv', 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
